#library & laod

```{r}
library(readxl)
library(tidyr)
library(lubridate)
library(forecast)
library(fpp)
install.packages("vars")
library(vars)
library(tidyverse)
NASA.data <- read_excel(file.choose(), sheet= "NASA")
UKMET.data <- read_excel(file.choose(), sheet= "UKMET")
#kingstone data
KON.data <- read.csv(file.choose())

NASA.Long <- pivot_longer(NASA.data, cols=2:13, names_to = "Month", values_to = "Temp Anomaly")
UKMET.Long <- pivot_longer(UKMET.data, cols=2:13, names_to = "Month", values_to = "Temp Anomaly")
```


```{r}
UKMET.Long$MoNum <- match(UKMET.Long$Month, month.abb)
UKMET.Long$Date <- make_date(year = UKMET.Long$Year, mont = UKMET.Long$MoNum)
UKMET.Long$Year <- NULL
UKMET.Long$Month <- NULL
UKMET.Long$MoNum <- NULL
UKMET.Long <- UKMET.Long[,c(2,1)]
UKMET.Long <- head(UKMET.Long, -11)
UKMET.Long$Temp <- UKMET.Long$`Temp Anomaly` + 13.974 
#from crudata.uea.ac.uk/cru/data/temperature/abs_glnhsh.txt Global Annual Temp
UKMET.Long$`Temp Anomaly` <- NULL

NASA.Long$MoNum <- match(NASA.Long$Month, month.abb)
NASA.Long$Date <- make_date(year = NASA.Long$Year, mont = NASA.Long$MoNum)
NASA.Long$Year <- NULL
NASA.Long$Month <- NULL
NASA.Long$MoNum <- NULL
NASA.Long <- NASA.Long[,c(2,1)]
NASA.Long <- head(NASA.Long, -9)
NASA.Long$Temp <- NASA.Long$`Temp Anomaly` + 14 
#provided by case, should double check
NASA.Long$`Temp Anomaly` <- NULL
```

```{r}
write.csv(NASA.Long, 'NASA.Long.csv')
write.csv(UKMET.Long, 'UKMET.Long.csv')
```


```{r}
NASA.TS <- ts(NASA.Long$Temp, start = 1880, frequency = 12)
fit <- decompose(NASA.TS, type="multiplicative") 
#decompose using "classical" method, multiplicative form
plot(fit)
fit <- decompose(NASA.TS, type="additive") 
#decompose using "classical" method, additive form
plot(fit)
fit <- stl(NASA.TS, t.window=12, s.window="periodic") 
#decompose using STL (Season and trend using Loess)
plot(fit)
plot(NASA.TS)
```


```{r}
NASA_AAN <- ets(NASA.TS, model="AAN")
NASA_AAZ <- ets(NASA.TS, model="AAZ", damped=FALSE)
NASA_MMN <- ets(NASA.TS, model="MMN", damped=FALSE)
NASA_MMZ <- ets(NASA.TS, model="MMZ", damped=FALSE) 
# Create their prediction "cones" for 960 months (80 years) into the future with quintile confidence intervals
NASA_AAN_pred <- forecast(NASA_AAN, h=960, level=c(0.8, 0.90))
NASA_AAZ_pred <- forecast(NASA_AAA, h=906, level=c(0.8, 0.90))
NASA_MMN_pred <- forecast(NASA_MMN, h=960, level=c(0.8, 0.90))
NASA_MMZ_pred <- forecast(NASA_MMZ, h=960, level=c(0.8, 0.90)) 
# Compare the prediction "cones" visually
par(mfrow=c(1,4)) 
# This command sets the plot window to show 1 row of 4 plots
plot(NASA_AAN_pred, xlab="Year", ylab="Temp")
plot(NASA_AAZ_pred, xlab="Year", ylab="Temp")
plot(NASA_MMN_pred, xlab="Year", ylab="Temp")
plot(NASA_MMZ_pred, xlab="Year", ylab="Temp")
#Models
NASA_AAN
NASA_AAZ
NASA_MMN
NASA_MMZ
```

#Create a trigonometric box-cox autoregressive trend seasonality (TBATS) model
```{r}
NASA_tbats <- tbats(NASA.TS)
NASA_tbats_pred <-forecast(NASA_tbats, h=960, level=c(0.8, 0.90))
par(mfrow=c(1,1))
plot(NASA_tbats_pred, xlab="Year", ylab="Predicted Temperature")

par(mfrow=c(1,3)) 
# Lets look at the three models with seasonality on one graph on the same scale
plot(NASA_AAN_pred, xlab="Year", ylab="Predited Temperature", ylim=c(10,20))
plot(NASA_AAZ_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(10,20))
plot(NASA_tbats_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(10,20))

NASA_tbats
```

#Comparing models -- Time series Cross Validation (Rolling Horizon Holdout)

```{r}
f_AAN  <- function(y, h) forecast(ets(y, model="AAN"), h = h)
errors_AAN <- tsCV(NASA.TS, f_AAN, h=1, window=60)
f_MMN  <- function(y, h) forecast(ets(y, model="MMN"), h = h)
errors_MMN <- tsCV(NASA.TS, f_MMN, h=1, window=60)
f_AAA  <- function(y, h) forecast(ets(y, model="AAA"), h = h)
errors_AAA <- tsCV(NASA.TS, f_AAA, h=1, window=60)
f_MMM  <- function(y, h) forecast(ets(y, model="MMM"), h = h)
errors_MMM <- tsCV(NASA.TS, f_MMM, h=1, window=60)
```

```{r}
par(mfrow=c(1,1)) 
plot(errors_AAN, ylab='tsCV errors')
abline(0,0)
lines(errors_MMN, col="red")
lines(errors_AAA, col="green")
lines(errors_MMM, col="blue")
legend("left", legend=c("CV_error_AAN", "CV_error_MMN","CV_error_AAA","CV_error_MMM"), col=c("black", "red", "green", "blue"), lty=1:4)
AAN_Test <- checkresiduals(NASA_AAN)
```

```{r}
mean(abs(errors_AAN/NASA.TS), na.rm=TRUE)*100 #Lowest ERROR
mean(abs(errors_MMN/NASA.TS), na.rm=TRUE)*100
mean(abs(errors_AAA/NASA.TS), na.rm=TRUE)*100
mean(abs(errors_MMM/NASA.TS), na.rm=TRUE)*100
f_TBATS  <- function(y, h) forecast(tbats(y), h = h)
errors_TBATS <- tsCV(NASA.TS, f_TBATS, h=1, window=60)
```

```{r}
plot(errors_AAN, ylab='tsCV errors', col="green")
abline(0,0)
lines(errors_MMN, col="blue")
lines(errors_TBATS, col="gray")
legend("left", legend=c("CV_error_AAA", "CV_error_MMM","CV_error_TBATS"), col=c("green", "blue", "gray"), lty=1:4)
```

```{r}
mean(abs(errors_TBATS/NASA.TS), na.rm=TRUE)*100
AAN_Test <- checkresiduals(NASA.Long_tbats)
# Print the mean and confidence intervals for the MMZ model
NASA_AAN_pred
plot()
```

#Write CSV for best fitting model
```{r}
write.csv(NASA_AAN_pred, 'NASA_AAN_pred.csv')
```

# DIFFERENCING and ARIMA
# we will use a10 dataset (comes with fpp - sales of antidiabetic drug in Australia)

```{r}
par(mfrow=c(1,3))
View(NASA.Long)
plot(NASA.Long, xlab="Year",
     ylab="Temperature")
plot(log(NASA.Long$Temp), xlab="Year",
     ylab="log Temp")
plot(diff(log(NASA.Long$Temp),12), xlab="Year",
     ylab="Annual change in log Temp")
fit <- stl(NASA.TS, t.window=12, s.window="periodic", robust=TRUE)
plot(fit)
```

# auto-correlation function

```{r}
Acf(NASA.TS,main="") 
# data "as is"
Acf(log(NASA.TS),main="") 
# log-transformed data
Acf(diff(NASA.TS,12),main="") 
# difference-12 log data
```

# partial auto-correlation function

```{r}
par(mfrow=c(1,2))
Acf(diff(NASA.TS,12),main="")
Pacf(diff(NASA.TS,12),main="") 
fit.auto.arima.no.season <- auto.arima(NASA.TS,seasonal=FALSE)
fit.auto.arima.no.season
fit.auto.arima.season <- auto.arima(NASA.TS,seasonal=TRUE)
fit.auto.arima.season
```

```{r}
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.no.season))
plot(forecast(fit.auto.arima.no.season,960)) 
#960 stands for 960 months = 80 years
auto.arima.no.season_prd <- forecast(fit.auto.arima.no.season,960)
auto.arima.no.season_prd

par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,960)) 
#960 stands for 960 months = 80 years
auto.arima.season_prd <- forecast(fit.auto.arima.season,960)
auto.arima.season_prd
```

```{r}
f_AANS  <- function(y, h) forecast(auto.arima(y), h = h)
errors_AANS <- tsCV(NASA.TS, f_AANS, h=1, window=60)
errors_AANS <- checkresiduals(fit.auto.arima.no.season)
errors_AAWS <- checkresiduals(fit.auto.arima.season)
errors_AANS <-fit.auto.arima.no.season %>% h = 12(1880-2021)+1) %>%
  accuracy(fit.auto.arima.no.season)
errors_AAWS <-fit.auto.arima.season %>% h = 12(1880-2021)+1) %>%
  accuracy(fit.auto.arima.season)
mean(abs(errors_AANS/NASA.TS), na.rm=TRUE)*100
mean(abs(errors_AAWS/NASA.TS), na.rm=TRUE)*100
```

```{r}
AAWS_pred <- forecast(fit.auto.arima.season, h=960, level=c(0.8, 0.90))
AAWS_pred
plot(AAWS_pred)
write.csv(AAWS_pred, 'AAWS.csv')
```

#Part III
#WFdata<-read.csv(file.choose(), header=TRUE, sep=",") #load the data
#str(WFdata) #check the structure of the data
# fix incorrectly classified data types
#WFdata$DOW <- as.factor(WFdata$DOW)
#WFdata$X15min_interval <- as.factor(WFdata$X15min_interval)
#summary(WFdata) #examine the descriptive statistics

```{r}
NASA.Long_msts <- msts (NASA.Long$Temp, seasonal.periods=c(12)) 
#define multiple-seasonality time series (time of day (15mins) and day of week)
```


##### TBATS

```{r}
NASA.Long_tbats <- tbats(NASA.Long_msts)
plot(NASA.Long_tbats) 
#plot decomposition
NASA.Long_tbats_pred <- forecast(NASA.Long_tbats, h=960, level=c(0.8, 0.90)) 
#predict 2 weeks out
plot(NASA.Long_tbats_pred, xlab="Time", ylab="Predicted Temperature, C")

```

##### Exponential smoothing 

```{r}
NASA.Long_AAN <- ets(NASA.Long_msts, model="AAN") 
#AAA cannot handle this, "Error in ets(WFdemand_msts, model = "AAA") : Frequency too high"
plot(NASA.Long_AAN)
NASA.Long_AAN_pred <- forecast(NASA.Long_AAN, h=960, level=c(0.8, 0.90))
plot(NASA.Long_AAN_pred, xlab="Time", ylab="Predicted Temperature, C")

NASA.Long_MMN <- ets(NASA.Long_msts, model="MMN") 
#MZZ cannot handle this, "Inappropriate model for data with negative or zero values"
plot(NASA.Long_MMN)
NASA.Long_MMN_pred <- forecast(NASA.Long_MMN, h=960, level=c(0.8, 0.90))
plot(NASA.Long_MMN_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### A "plain vanilla" ARIMA

```{r}
NASA.Long_arima <- auto.arima(NASA.Long_msts,seasonal=TRUE)
NASA.Long_arima_pred <- forecast(NASA.Long_arima, h=960, level=c(0.8, 0.90))
plot(NASA.Long_arima_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### ARIMA with regressors We are playing with the idea of adding a regressor for human population

```{r}
#weekdayMatrix <- cbind(Weekday=model.matrix(~as.factor(WFdata$DOW))) # Create dummies for each day-of-week
#weekdayMatrix <- weekdayMatrix[,-1]# Remove "intercept" (7th day) dummy
#colnames(weekdayMatrix) <- c("Mon","Tue","Wed","Thu","Fri","Sat") # Rename columns
#matrix_of_regressors <- weekdayMatrix
#X15minMatrix <- cbind(X15min=model.matrix(~as.factor(WFdata$X15min_interval)))
#X15minMatrix <- X15minMatrix[,-1]
#matrix_of_regressors <- cbind(weekdayMatrix,X15minMatrix)
#WFdemand_arima <- auto.arima(WFdata$Electricity.Demand.for.the.Branch..kw.,xreg=matrix_of_regressors) #Train a model 
#WFdemand_arima # See what it is
#xreg.pred<-matrix_of_regressors[-c(1345:5664),] # Build a 2-weeks-out prediction matrix
#WFdemand_arima_pred <- forecast(WFdemand_arima, h=1344, xreg = xreg.pred, level=c(0.8, 0.95))
#plot(WFdemand_arima_pred, xlab="Time", ylab="Predicted Electricity Demand, kW", ylim=c(0,20))
```

##### ARIMA on residuals

```{r}
NASA.Long2_msts <- tslm(NASA.Long_msts ~ trend + season) 
# Build a linear model for trend and seasonality
summary(NASA.Long2_msts)

residarima1 <- auto.arima(NASA.Long2_msts$residuals) 
# Build ARIMA on it's residuals
residarima1
residualsArimaForecast <- forecast(residarima1, h=960) 
#forecast from ARIMA
residualsF <- as.numeric(residualsArimaForecast$mean)

regressionForecast <- forecast(NASA.Long_msts,h=960) 
#forecast from lm
regressionF <- as.numeric(regressionForecast$mean)

forecastR <- regressionF+residualsF 
# Total prediction
print(forecastR)
plot(forecastR)
for (i in 1:1695){points(i+1695,forecastR[i],col="red",pch=19, cex=0.5)}
```

#compare with TBATS

```{r}
plot(NASA.Long_tbats_pred, xlab="Time", ylab="Predicted Temp, C")
for (i in 1:1695){points((i+1695),forecastR[i],col="red",pch=19, cex=0.5)}
```

##### Rolling-horizon holdout: TBATS

```{r}
NASA.Long_msts
accuracy.tbats=0 # we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(NASA.Long_msts)- nTest - 1
  nTrain
  train <- window(NASA.Long_msts, start=1, end=1+((nTrain)/12))
  train
  test <- window(NASA.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  test
  s <- tbats(train)
  sp<- predict(s,h=12)
  
  cat("----------------------------------
    
    Data Partition",i,"
    
    Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
    Test Set includes 12 time periods. Observations", nTrain+1, "to", nTrain+12,"
    
    ")
  print(accuracy(sp,test))
  
  accuracy.tbats<-rbind(accuracy.tbats,accuracy(sp,test)[2,5])
  
#print(sp$model)
}
accuracy.tbats<-accuracy.tbats[-1] 
NASA.Long_msts_pred <- forecast(NASA.Long_msts,960)
NASA.Long_msts_pred
```

##### Rolling-horizon holdout: ARIMA on residuals

```{r}
accuracy.arima=0 
# we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(NASA.Long_msts)- nTest -1
  train <- window(NASA.Long_msts, start=1, end=1+(nTrain)/(12))
  test <- window(NASA.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  
  train
  trainlm <- tslm(train ~ trend + season)
  trainlmf <- forecast(trainlm,h=960)
  
  residauto <- auto.arima(trainlm$residuals)
  residf <- forecast(residauto,h=960)
  
  y <- as.numeric(trainlmf$mean)
  x <- as.numeric(residf$mean)
  sp <- x+y
  
  cat("----------------------------------
      
      Data Partition",i,"
      
      Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
      Test Set includes 96 time periods. Observations", nTrain+1, "to", nTrain+12,"
      
      ")
  
  print(accuracy(sp,test))
}
```

#  print(residauto)

```{r}
accuracy.arima<-rbind(accuracy.arima,accuracy(sp,test)[1,5])
```

#print(sp$model)

```{r}
accuracy.arima<-accuracy.arima[-1]

#compare mean accuracies of the rolling holdout
mean(accuracy.tbats)
mean(accuracy.arima)

sd(accuracy.tbats)
sd(accuracy.arima)
```

##### Correlated time-series -- Vectorized Auto-regressions (VARS) We can't use VARS as we only have one column of time series data


```{r}
#cor(NASA.Long[2],NASA.Long[3])
#series <- ts(cbind(WFdata[2],WFdata[3]))
#plot(series)

# Estimate and summarize the model
#model.VAR <- VAR(series,96,type="none") 
#summary(model.VAR)

# Impulse responses (if one series changes, what happens to the other?)
#impulse.response <- irf(model.VAR,impulse="Solar.System.Output..kWh.",response="Electricity.Demand.for.the.Branch..kw.",n.ahead = 96,ortho = FALSE, cumulative = FALSE)
#plot(impulse.response)

# Predict next week and plot the results
#predicted.values.VAR<-predict(model.VAR, n.ahead=672,ci=0.8)
#plot(predicted.values.VAR,xlim=c(5000,6500))

#UKMET Data#
```

```{r}
UKMET.TS <- ts(UKMET.Long$Temp, start = 1850, frequency = 12)
fit <- decompose(UKMET.TS, type="multiplicative") 
#decompose using "classical" method, multiplicative form
plot(fit)
fit <- decompose(UKMET.TS, type="additive") 
#decompose using "classical" method, additive form
plot(fit)
fit <- stl(UKMET.TS, t.window=12, s.window="periodic") 
#decompose using STL (Season and trend using Loess)
plot(fit)
plot(UKMET.TS)
```


```{r}
UKMET_AAN <- ets(UKMET.TS, model="AAN")
UKMET_AAZ <- ets(UKMET.TS, model="AAZ", damped=FALSE)
UKMET_MMN <- ets(UKMET.TS, model="MMN", damped=FALSE)
UKMET_MMZ <- ets(UKMET.TS, model="MMZ", damped=FALSE) 
```

# Create their prediction "cones" for 960 months (80 years) into the future with quintile confidence intervals


```{r}
UKMET_AAN_pred <- forecast(UKMET_AAN, h=960, level=c(0.8, 0.90))
UKMET_AAZ_pred <- forecast(UKMET_AAZ, h=906, level=c(0.8, 0.90))
UKMET_MMN_pred <- forecast(UKMET_MMN, h=960, level=c(0.8, 0.90))
UKMET_MMZ_pred <- forecast(UKMET_MMZ, h=960, level=c(0.8, 0.90)) 
```

# Compare the prediction "cones" visually

# This command sets the plot window to show 1 row of 4 plots
```{r}
par(mfrow=c(1,4)) 
plot(UKMET_AAN_pred, xlab="Year", ylab="Temp")
plot(UKMET_AAZ_pred, xlab="Year", ylab="Temp")
plot(UKMET_MMN_pred, xlab="Year", ylab="Temp")
plot(UKMET_MMZ_pred, xlab="Year", ylab="Temp")
```

#Models

```{r}
UKMET_AAN
UKMET_AAZ
UKMET_MMN
UKMET_MMZ
```

#Create a trigonometric box-cox autoregressive trend seasonality (TBATS) model

```{r}
UKMET_tbats <- tbats(UKMET.TS)
UKMET_tbats_pred <-forecast(UKMET_tbats, h=960, level=c(0.8, 0.95))
par(mfrow=c(1,1))
plot(UKMET_tbats_pred, xlab="Year", ylab="Predicted Temperature")
```

# Lets look at the three models with seasonality on one graph on the same scale
```{r}
par(mfrow=c(1,3))
plot(UKMET_AAN_pred, xlab="Year", ylab="Predited Temperature", ylim=c(10,20))
plot(UKMET_AAZ_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(10,20))
plot(UKMET_tbats_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(10,20))
UKMET_tbats
```

### Comparing models -- Time series Cross Validation (Rolling Horizon Holdout)

```{r}
f_AAN  <- function(y, h) forecast(ets(y, model="AAN"), h = h)
errors_AAN <- tsCV(UKMET.TS, f_AAN, h=1, window=60)
f_MMN  <- function(y, h) forecast(ets(y, model="MMN"), h = h)
errors_MMN <- tsCV(UKMET.TS, f_MMN, h=1, window=60)
f_AAA  <- function(y, h) forecast(ets(y, model="AAA"), h = h)
errors_AAA <- tsCV(UKMET.TS, f_AAA, h=1, window=60)
f_MMM  <- function(y, h) forecast(ets(y, model="MMM"), h = h)
errors_MMM <- tsCV(UKMET.TS, f_MMM, h=1, window=60)
```

```{r}
par(mfrow=c(1,1)) 
plot(errors_AAN, ylab='tsCV errors')
abline(0,0)
lines(errors_MMN, col="red")
lines(errors_AAA, col="green")
lines(errors_MMM, col="blue")
legend("left", legend=c("CV_error_AAN", "CV_error_MMN","CV_error_AAA","CV_error_MMM"), col=c("black", "red", "green", "blue"), lty=1:4)
```


```{r}
mean(abs(errors_AAN/UKMET.TS), na.rm=TRUE)*100 #Lowest ERROR
mean(abs(errors_MMN/UKMET.TS), na.rm=TRUE)*100
mean(abs(errors_AAA/UKMET.TS), na.rm=TRUE)*100
mean(abs(errors_MMM/UKMET.TS), na.rm=TRUE)*100
```


```{r}
f_TBATS  <- function(y, h) forecast(tbats(y), h = h)
errors_TBATS <- tsCV(UKMET.TS, f_TBATS, h=1, window=60)
```


```{r}
plot(errors_AAA, ylab='tsCV errors', col="green")
abline(0,0)
lines(errors_MMN, col="blue")
lines(errors_TBATS, col="gray")
legend("left", legend=c("CV_error_AAA", "CV_error_MMM","CV_error_TBATS"), col=c("green", "blue", "gray"), lty=1:4)
```


```{r}
mean(abs(errors_TBATS/UKMET.TS), na.rm=TRUE)*100
```

# Print the mean and confidence intervals for the MMZ model
#UKMET_AAN_pred

# DIFFERENCING and ARIMA
# we will use a10 dataset (comes with fpp - sales of antidiabetic drug in Australia)
```{r}
par(mfrow=c(1,3))
View(UKMET.Long)
plot(UKMET.Long, xlab="Year",
     ylab="Temperature")
plot(log(UKMET.Long$Temp), xlab="Year",
     ylab="log Temp")
plot(diff(log(UKMET.Long$Temp),12), xlab="Year",
     ylab="Annual change in log Temp")
fit <- stl(UKMET.TS, t.window=12, s.window="periodic", robust=TRUE)
plot(fit)
```

# auto-correlation function

```{r}
Acf(UKMET.TS,main="") # data "as is"
Acf(log(UKMET.TS),main="") # log-transformed data
Acf(diff(UKMET.TS,12),main="") # difference-12 log data
```

# partial auto-correlation function

```{r}
par(mfrow=c(1,2))
Acf(diff(UKMET.TS,12),main="")
Pacf(diff(UKMET.TS,12),main="") 
```




```{r}
fit.auto.arima.no.season <- auto.arima(UKMET.TS,seasonal=FALSE)
fit.auto.arima.no.season

fit.auto.arima.season <- auto.arima(UKMET.TS,seasonal=TRUE)
fit.auto.arima.season

par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.no.season))
plot(forecast(fit.auto.arima.no.season,960)) 
#960 stands for 960 months = 80 years
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.no.season))
plot(forecast(fit.auto.arima.no.season,960)) 
#960 stands for 960 months = 80 years
```




```{r}
errors_AANS <-fit.auto.arima.no.season %>% h = 12(1850-2021)+1) accuracy(fit.auto.arima.no.season)

errors_AAWS <-fit.auto.arima.season %>% h = 12(1850-2021)+1) %>% accuracy(fit.auto.arima.season)

AAWS_pred <- forecast(fit.auto.arima.season, h=960, level=c(0.8, 0.90))
AAWS_pred
plot(AAWS_pred)
write.csv(AAWS_pred, 'AAWS.csv')
```

#Part III

```{r}
#WFdata<-read.csv(file.choose(), header=TRUE, sep=",") #load the data
#str(WFdata) #check the structure of the data
# fix incorrectly classified data types
#WFdata$DOW <- as.factor(WFdata$DOW)
#WFdata$X15min_interval <- as.factor(WFdata$X15min_interval)
#summary(WFdata) #examine the descriptive statistics
```

#define multiple-seasonality time series (time of day (15mins) and day of week)

```{r}
UKMET.Long_msts <- msts (UKMET.Long$Temp, seasonal.periods=c(12)) 
```

##### TBATS

```{r}
UKMET.Long_tbats <- tbats(UKMET.Long_msts)
plot(UKMET.Long_tbats) #plot decomposition
UKMET.Long_tbats_pred <- forecast(UKMET.Long_tbats, h=960, level=c(0.8, 0.90)) 
#predict 2 weeks out
plot(UKMET.Long_tbats_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### Exponential smoothing 

```{r}
UKMET.Long_AAN <- ets(UKMET.Long_msts, model="AAN") 
#AAA cannot handle this, "Error in ets(WFdemand_msts, model = "AAA") : Frequency too high"
plot(UKMET.Long_AAN)
UKMET.Long_AAN_pred <- forecast(UKMET.Long_AAN, h=960, level=c(0.8, 0.90))
plot(UKMET.Long_AAN_pred, xlab="Time", ylab="Predicted Temperature, C")

UKMET.Long_MMN <- ets(UKMET.Long_msts, model="MMN") 
#MZZ cannot handle this, "Inappropriate model for data with negative or zero values"
plot(UKMET.Long_MMN)
UKMET.Long_MMN_pred <- forecast(UKMET.Long_MMN, h=960, level=c(0.8, 0.90))
plot(UKMET.Long_MMN_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### A "plain vanilla" ARIMA

```{r}
UKMET.Long_arima <- auto.arima(UKMET.Long_msts,seasonal=TRUE)
UKMET.Long_arima_pred <- forecast(UKMET.Long_arima, h=960, level=c(0.8, 0.95))
plot(UKMET.Long_arima_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### ARIMA with regressors We are playing with the idea of adding a regressor for human population

```{r}
#weekdayMatrix <- cbind(Weekday=model.matrix(~as.factor(WFdata$DOW))) 
# Create dummies for each day-of-week
#weekdayMatrix <- weekdayMatrix[,-1]# Remove "intercept" (7th day) dummy
#colnames(weekdayMatrix) <- c("Mon","Tue","Wed","Thu","Fri","Sat") # Rename columns
```




```{r}
#matrix_of_regressors <- weekdayMatrix

#X15minMatrix <- cbind(X15min=model.matrix(~as.factor(WFdata$X15min_interval)))
#X15minMatrix <- X15minMatrix[,-1]
#matrix_of_regressors <- cbind(weekdayMatrix,X15minMatrix)
```



```{r}
#WFdemand_arima <- auto.arima(WFdata$Electricity.Demand.for.the.Branch..kw., xreg=matrix_of_regressors) # Train a model 
#WFdemand_arima # See what it is

#xreg.pred<-matrix_of_regressors[-c(1345:5664),] # Build a 2-weeks-out prediction matrix

#WFdemand_arima_pred <- forecast(WFdemand_arima, h=1344, xreg = xreg.pred, level=c(0.8, 0.95))
#plot(WFdemand_arima_pred, xlab="Time", ylab="Predicted Electricity Demand, kW", ylim=c(0,20))
```

##### ARIMA on residuals

```{r}
UKMET.Long2_msts <- tslm(UKMET.Long_msts ~ trend + season) 
# Build a linear model for trend and seasonality
summary(UKMET.Long_msts)

residarima1 <- auto.arima(UKMET.Long2_msts$residuals) 
# Build ARIMA on it's residuals
residarima1
residualsArimaForecast <- forecast(residarima1, h=960) 
#forecast from ARIMA
residualsF <- as.numeric(residualsArimaForecast$mean)

regressionForecast <- forecast(UKMET.Long_msts,h=960) 
#forecast from lm
regressionF <- as.numeric(regressionForecast$mean)

forecastR <- regressionF+residualsF 
# Total prediction
print(forecastR)
plot(forecastR)
for (i in 1:1695){points(i+1695,forecastR[i],col="red",pch=19, cex=0.5)}
```

#compare with TBATS

```{r}
plot(UKMET.Long_tbats_pred, xlab="Time", ylab="Predicted Temp, C")
for (i in 1:1695){points((i+1695),forecastR[i],col="red",pch=19, cex=0.5)}
```

##### Rolling-horizon holdout: TBATS


```{r}
UKMET.Long_msts
accuracy.tbats=0 
# we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(UKMET.Long_msts)- nTest - 1
  nTrain
  train <- window(UKMET.Long_msts, start=1, end=1+((nTrain)/12))
  train
  test <- window(UKMET.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  test
  s <- tbats(train)
  sp<- predict(s,h=12)
  
  cat("----------------------------------
    
    Data Partition",i,"
    
    Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
    Test Set includes 12 time periods. Observations", nTrain+1, "to", nTrain+12,"
    
    ")
  print(accuracy(sp,test))
  
  accuracy.tbats<-rbind(accuracy.tbats,accuracy(sp,test)[2,5])
  
  #print(sp$model)
}
accuracy.tbats<-accuracy.tbats[-1] 
```

##### Rolling-horizon holdout: ARIMA on residuals

```{r}
accuracy.arima=0 # we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(UKMET.Long_msts)- nTest -1
  train <- window(UKMET.Long_msts, start=1, end=1+(nTrain)/(12))
  test <- window(UKMET.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  
  train
  trainlm <- tslm(train ~ trend + season)
  trainlmf <- forecast(trainlm,h=960)
  
  residauto <- auto.arima(trainlm$residuals)
  residf <- forecast(residauto,h=960)
  
  y <- as.numeric(trainlmf$mean)
  x <- as.numeric(residf$mean)
  sp <- x+y
  
  cat("----------------------------------
      
      Data Partition",i,"
      
      Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
      Test Set includes 96 time periods. Observations", nTrain+1, "to", nTrain+12,"
      
      ")
  
  print(accuracy(sp,test))
  #  print(residauto)
  
  accuracy.arima<-rbind(accuracy.arima,accuracy(sp,test)[1,5])
  
  #print(sp$model)
}
accuracy.arima<-accuracy.arima[-1]
```

#compare mean accuracies of the rolling holdout

```{r}
mean(accuracy.tbats)
mean(accuracy.arima)

sd(accuracy.tbats)
sd(accuracy.arima)
```

##### Correlated time-series -- Vectorized Auto-regressions (VARS) We can't use VARS as we only have #one column of time series data

```{r}
#cor(UKMET.Long[2],UKMET.Long[3])

#series <- ts(cbind(WFdata[2],WFdata[3]))
#plot(series)

# Estimate and summarize the model
#model.VAR <- VAR(series,96,type="none") 
#summary(model.VAR)

# Impulse responses (if one series changes, what happens to the other?)
#impulse.response <- irf(model.VAR,impulse="Solar.System.Output..kWh.",response="Electricity.Demand.for.the.Branch..kw.",n.ahead = 96,ortho = FALSE, cumulative = FALSE)
#plot(impulse.response)

```

# Predict next week and plot the results

```{r}
#predicted.values.VAR<-predict(model.VAR, n.ahead=672,ci=0.8)
#plot(predicted.values.VAR,xlim=c(5000,6500))
```

#Kingston, ON

```{r}
KON.Long <- head(KON.data, -24)
KON.Long$TempK <- KON.Long$temp + 272.15
KON.Long$temp <- NULL
```


```{r}
KON.TS <- ts(KON.Long$TempK, start = 1880, frequency = 12)

fit <- decompose(KON.TS, type="multiplicative") 
#decompose using "classical" method, multiplicative form
plot(fit)
fit <- decompose(KON.TS, type="additive") 
#decompose using "classical" method, additive form
plot(fit)
fit <- stl(KON.TS, t.window=12, s.window="periodic") 
#decompose using STL (Season and trend using Loess)
plot(fit)
plot(KON.TS)
```


```{r}
KON_AAN <- ets(KON.TS, model="AAN")
KON_AAZ <- ets(KON.TS, model="AAZ", damped=FALSE)
KON_MMN <- ets(KON.TS, model="MMN", damped=FALSE)
KON_MMZ <- ets(KON.TS, model="MMZ", damped=FALSE) 
KON_MMM <- ets(KON.TS, model="MMM", damped=FALSE)
```

# Create their prediction "cones" for 960 months (80 years) 
#into the future with quintile confidence intervals

```{r}
KON_AAN_pred <- forecast(KON_AAN, h=960, level=c(0.8, 0.90))
KON_AAZ_pred <- forecast(KON_AAZ, h=906, level=c(0.8, 0.90))
KON_MMN_pred <- forecast(KON_MMN, h=960, level=c(0.8, 0.90))
KON_MMZ_pred <- forecast(KON_MMZ, h=960, level=c(0.8, 0.90))
KON_MMM_pred <- forecast(KON_MMZ, h=960, level=c(0.8, 0.90))
```

# Compare the prediction "cones" visually
# This command sets the plot window to show 1 row of 4 plots

```{r}
par(mfrow=c(1,4)) 
plot(KON_AAN_pred, xlab="Year", ylab="Temp")
plot(KON_AAZ_pred, xlab="Year", ylab="Temp")
plot(KON_MMN_pred, xlab="Year", ylab="Temp")
plot(KON_MMZ_pred, xlab="Year", ylab="Temp")
plot(KON_MMM_pred, xlab="Year", ylab="Temp")
```

#Models

```{r}
KON_AAN
KON_AAZ
KON_MMN
KON_MMZ
```

#Create a trigonometric box-cox autoregressive trend seasonality (TBATS) model

```{r}
KON_tbats <- tbats(KON.TS)
KON_tbats_pred <-forecast(KON_tbats, h=972, level=c(0.8, 0.90))
par(mfrow=c(1,1))
plot(KON_tbats_pred, xlab="Year", ylab="Predicted Temperature")
```


```{r}
par(mfrow=c(1,3)) 
# Lets look at the three models with seasonality on one graph on the same scale
plot(KON_AAN_pred, xlab="Year", ylab="Predited Temperature", ylim=c(240,300))
plot(KON_AAZ_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(240,300))
plot(KON_tbats_pred, xlab="Year", ylab="Predicted Temperature", ylim=c(250,300))
```



```{r}
KON_tbats_pred
write.csv(KON_tbats_pred, 'KON_tbats_pred.csv')
```

### Comparing models -- Time series Cross Validation (Rolling Horizon Holdout)

```{r}
f_AAN  <- function(y, h) forecast(ets(y, model="AAN"), h = h)
errors_AAN <- tsCV(KON.TS, f_AAN, h=1, window=60)
f_MMN  <- function(y, h) forecast(ets(y, model="MMN"), h = h)
errors_MMN <- tsCV(KON.TS, f_MMN, h=1, window=60)
f_AAA  <- function(y, h) forecast(ets(y, model="AAA"), h = h)
errors_AAA <- tsCV(KON.TS, f_AAA, h=1, window=60)
f_MMM  <- function(y, h) forecast(ets(y, model="MMM"), h = h)
errors_MMM <- tsCV(KON.TS, f_MMM, h=1, window=60)
```



```{r}
par(mfrow=c(1,1)) 
plot(errors_AAN, ylab='tsCV errors')
abline(0,0)
lines(errors_MMN, col="red")
lines(errors_AAA, col="green")
lines(errors_MMM, col="blue")
legend("left", legend=c("CV_error_AAN", "CV_error_MMN","CV_error_AAA","CV_error_MMM"), col=c("black", "red", "green", "blue"), lty=1:4)
```




```{r}
mean(abs(errors_AAN/KON.TS), na.rm=TRUE)*100 
mean(abs(errors_MMN/KON.TS), na.rm=TRUE)*100
mean(abs(errors_AAA/KON.TS), na.rm=TRUE)*100 
mean(abs(errors_MMM/KON.TS), na.rm=TRUE)*100 
#Lowest Error
```



```{r}
f_TBATS  <- function(y, h) forecast(tbats(y), h = h)
errors_TBATS <- tsCV(KON.TS, f_TBATS, h=1, window=60) #takes too long to run

plot(errors_AAA, ylab='tsCV errors', col="green")
abline(0,0)
lines(errors_MMN, col="blue")
lines(errors_TBATS, col="gray")
legend("left", legend=c("CV_error_AAA", "CV_error_MMM","CV_error_TBATS"), col=c("green", "blue", "gray"), lty=1:4)

mean(abs(errors_TBATS/KON.TS), na.rm=TRUE)*100
```

# Print the mean and confidence intervals for the MMZ model

```{r}
KON_MMZ_pred
```

# DIFFERENCING and ARIMA
# we will use a10 dataset (comes with fpp - sales of antidiabetic drug in Australia)

```{r}
par(mfrow=c(1,3))
View(KON.Long)
plot(KON.Long, xlab="Year",
     ylab="Temperature")
plot(log(KON.Long$Temp), xlab="Year",
     ylab="log Temp")
plot(diff(log(KON.Long$Temp),12), xlab="Year",
     ylab="Annual change in log Temp")

fit <- stl(KON.TS, t.window=12, s.window="periodic", robust=TRUE)
plot(fit)
```

# auto-correlation function

```{r}
Acf(KON.TS,main="") 
# data "as is"
Acf(log(KON.TS),main="") 
# log-transformed data
Acf(diff(KON.TS,12),main="")
# difference-12 log data
```

# partial auto-correlation function

```{r}
par(mfrow=c(1,2))
Acf(diff(KON.TS,12),main="")
Pacf(diff(KON.TS,12),main="") 
```


```{r}
fit.auto.arima.no.season <- auto.arima(KON.TS,seasonal=FALSE)
fit.auto.arima.no.season

fit.auto.arima.season <- auto.arima(KON.TS,seasonal=TRUE)
fit.auto.arima.season
```


```{r}
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.no.season))
plot(forecast(fit.auto.arima.no.season,960)) 
#960 stands for 960 months = 80 years

par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,960)) 
#960 stands for 960 months = 80 years
```


```{r}
auto.arima.season_prd <- forecast(fit.auto.arima.season,960)
auto.arima.season_prd
f_AANS  <- function(y, h) forecast(auto.arima(y), h = h)
errors_AANS <- tsCV(NASA.TS, f_AANS, h=1, window=60)
errors_AANS <- checkresiduals(fit.auto.arima.no.season)
errors_AAWS <- checkresiduals(fit.auto.arima.season)
```




```{r}
errors_AANS <-fit.auto.arima.no.season > h = 12((1880-2021)+1) >
  accuracy(fit.auto.arima.no.season)

errors_AAWS <-fit.auto.arima.season > h = 12((1880-2021)+1) >
  accuracy(fit.auto.arima.season)

mean(abs(errors_AANS/NASA.TS), na.rm=TRUE)*100
mean(abs(errors_AAWS/NASA.TS), na.rm=TRUE)*100
```



```{r}
AAWS_pred <- forecast(fit.auto.arima.season, h=960, level=c(0.8, 0.90))
AAWS_pred
plot(AAWS_pred)
write.csv(AAWS_pred, 'AAWS.csv')
```

#Part III

```{r}
#WFdata<-read.csv(file.choose(), header=TRUE, sep=",") #load the data

#str(WFdata) #check the structure of the data

# fix incorrectly classified data types
#WFdata$DOW <- as.factor(WFdata$DOW)
#WFdata$X15min_interval <- as.factor(WFdata$X15min_interval)
#summary(WFdata) #examine the descriptive statistics
```

#define multiple-seasonality time series (time of day (15mins) and day of week)

```{r}
KON.Long_msts <- msts (KON.Long$Temp, seasonal.periods=c(12)) 
```

##### TBATS

```{r}
KON.Long_tbats <- tbats(KON.Long_msts)
plot(KON.Long_tbats) 
#plot decomposition
KON.Long_tbats_pred <- forecast(KON.Long_tbats, h=960, level=c(0.8, 0.90)) 
#predict 2 weeks out
plot(KON.Long_tbats_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### Exponential smoothing 
```{r}

KON.Long_AAN <- ets(KON.Long_msts, model="AAN") 
#AAA cannot handle this, "Error in ets(WFdemand_msts, model = "AAA") : Frequency too high"
plot(KON.Long_AAN)
KON.Long_AAN_pred <- forecast(KON.Long_AAN, h=960, level=c(0.8, 0.90))
plot(KON.Long_AAN_pred, xlab="Time", ylab="Predicted Temperature, C")

KON.Long_MMN <- ets(KON.Long_msts, model="MMN") 
#MZZ cannot handle this, "Inappropriate model for data with negative or zero values"
plot(KON.Long_MMN)
KON.Long_MMN_pred <- forecast(KON.Long_MMN, h=960, level=c(0.8, 0.90))
plot(KON.Long_MMN_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### A "plain vanilla" ARIMA

```{r}
KON.Long_arima <- auto.arima(KON.Long_msts,seasonal=TRUE)
KON.Long_arima_pred <- forecast(KON.Long_arima, h=960, level=c(0.8, 0.90))
plot(KON.Long_arima_pred, xlab="Time", ylab="Predicted Temperature, C")
```

##### ARIMA with regressors We are playing with the idea of adding a regressor for human population

```{r}
#weekdayMatrix <- cbind(Weekday=model.matrix(~as.factor(WFdata$DOW))) # Create dummies for each day-of-week
#weekdayMatrix <- weekdayMatrix[,-1]# Remove "intercept" (7th day) dummy
#colnames(weekdayMatrix) <- c("Mon","Tue","Wed","Thu","Fri","Sat") # Rename columns
```



```{r}
#matrix_of_regressors <- weekdayMatrix

#X15minMatrix <- cbind(X15min=model.matrix(~as.factor(WFdata$X15min_interval)))
#X15minMatrix <- X15minMatrix[,-1]
#matrix_of_regressors <- cbind(weekdayMatrix,X15minMatrix)

#WFdemand_arima <- auto.arima(WFdata$Electricity.Demand.for.the.Branch..kw., xreg=matrix_of_regressors) # Train a model 
#WFdemand_arima # See what it is

#xreg.pred<-matrix_of_regressors[-c(1345:5664),] # Build a 2-weeks-out prediction matrix

#WFdemand_arima_pred <- forecast(WFdemand_arima, h=1344, xreg = xreg.pred, level=c(0.8, 0.95))
#plot(WFdemand_arima_pred, xlab="Time", ylab="Predicted Electricity Demand, kW", ylim=c(0,20))
```

##### ARIMA on residuals


```{r}
KON.Long2_msts <- tslm(KON.Long_msts ~ trend + season) 
# Build a linear model for trend and seasonality
summary(KON.Long_msts)

residarima1 <- auto.arima(KON.Long2_msts$residuals) 
# Build ARIMA on it's residuals
residarima1
residualsArimaForecast <- forecast(residarima1, h=960) 
#forecast from ARIMA
residualsF <- as.numeric(residualsArimaForecast$mean)
```


```{r}
regressionForecast <- forecast(KON.Long_msts,h=960) 
#forecast from lm
regressionF <- as.numeric(regressionForecast$mean)

forecastR <- regressionF+residualsF 
# Total prediction
print(forecastR)
plot(forecastR)
for (i in 1:1695){points(i+1695,forecastR[i],col="red",pch=19, cex=0.5)}

#compare with TBATS
plot(KON.Long_tbats_pred, xlab="Time", ylab="Predicted Temp, C")
for (i in 1:1695){points((i+1695),forecastR[i],col="red",pch=19, cex=0.5)}
```

##### Rolling-horizon holdout: TBATS

```{r}
KON.Long_msts
accuracy.tbats=0 
# we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(KON.Long_msts)- nTest - 1
  nTrain
  train <- window(KON.Long_msts, start=1, end=1+((nTrain)/12))
  train
  test <- window(KON.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  test
  s <- tbats(train)
  sp<- predict(s,h=12)
  
  cat("----------------------------------
    
    Data Partition",i,"
    
    Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
    Test Set includes 12 time periods. Observations", nTrain+1, "to", nTrain+12,"
    
    ")
  print(accuracy(sp,test))
  
  accuracy.tbats<-rbind(accuracy.tbats,accuracy(sp,test)[2,5])
  
  #print(sp$model)
}
accuracy.tbats<-accuracy.tbats[-1] 

```

##### Rolling-horizon holdout: ARIMA on residuals

```{r}
accuracy.arima=0 # we will check average 1-day-out accuracy for 7 days
for (i in 1:12)
{ 
  nTest <- 1*i  
  nTrain <- length(KON.Long_msts)- nTest -1
  train <- window(KON.Long_msts, start=1, end=1+(nTrain)/(12))
  test <- window(KON.Long_msts, start=1+(nTrain+1)/(12), end=1+(nTrain+12)/(12))
  
  train
  trainlm <- tslm(train ~ trend + season)
  trainlmf <- forecast(trainlm,h=960)
  
  residauto <- auto.arima(trainlm$residuals)
  residf <- forecast(residauto,h=960)
  
  y <- as.numeric(trainlmf$mean)
  x <- as.numeric(residf$mean)
  sp <- x+y
  
  cat("----------------------------------
      
      Data Partition",i,"
      
      Training Set includes",nTrain," time periods. Observations 1 to", nTrain, "
      Test Set includes 96 time periods. Observations", nTrain+1, "to", nTrain+12,"
      
      ")
  
  print(accuracy(sp,test))
  #  print(residauto)
  
  accuracy.arima<-rbind(accuracy.arima,accuracy(sp,test)[1,5])
  
  #print(sp$model)
}
accuracy.arima<-accuracy.arima[-1]
```

#compare mean accuracies of the rolling holdout

```{r}
mean(accuracy.tbats)
mean(accuracy.arima)

sd(accuracy.tbats)
sd(accuracy.arima)
```

##### Correlated time-series -- Vectorized Auto-regressions (VARS) We can't use VARS as we only have one column of time series data

```{r}
#install.packages("vars") #install.packages("strucchange")
#library(vars) # Load package

#cor(KON.Long[2],KON.Long[3])

#series <- ts(cbind(WFdata[2],WFdata[3]))
#plot(series)

# Estimate and summarize the model
#model.VAR <- VAR(series,96,type="none") 
#summary(model.VAR)
```


```{r}
# Impulse responses (if one series changes, what happens to the other?)
#impulse.response <- irf(model.VAR,impulse="Solar.System.Output..kWh.",response="Electricity.Demand.for.the.Branch..kw.",n.ahead = 96,ortho = FALSE, cumulative = FALSE)
#plot(impulse.response)

# Predict next week and plot the results
#predicted.values.VAR<-predict(model.VAR, n.ahead=672,ci=0.8)
#plot(predicted.values.VAR,xlim=c(5000,6500))
```



```{r}
#set.seed(96)
#inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

#training <- filteredDescr[inTrain,]
#test <- filteredDescr[-inTrain,]
#trainMDRR <- mdrrClass[inTrain]
#testMDRR <- mdrrClass[-inTrain]

```



```{r}

#preProcValues <- preProcess(training, method = c("center", "scale"))

#trainTransformed <- predict(preProcValues, training)
#testTransformed <- predict(preProcValues, test)
```


#NASA & UKMET 2007

```{r}
NASA.pre2007 <- head(NASA.Long,-171)

NASA.pre2007.TS <- ts(NASA.pre2007$Temp, start = 1880, frequency = 12)

fit.auto.arima.season <- auto.arima(NASA.pre2007.TS,seasonal=TRUE)
fit.auto.arima.season

par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,132)) 
#120 stands for 120 months = 10 years
```



```{r}
NASA.pre2007.10yrpred <- forecast(fit.auto.arima.season,h=132, level=c(0.8, 0.90))
plot(NASA.pre2007.10yrpred)
write.csv(NASA.pre2007.10yrpred, 'NASA.pre2007.csv')
UKMET.pre2007 <- head(UKMET.Long,-169)
UKMET.pre2007.TS <- ts(UKMET.pre2007$Temp, start = 1850, frequency = 12)
fit.auto.arima.season <- auto.arima(UKMET.pre2007.TS,seasonal=TRUE)
fit.auto.arima.season
```



```{r}
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,132)) #120 stands for 120 months = 10 years

UKMET.pre2007.10yrpred <- forecast(fit.auto.arima.season,h=132, level=c(0.8, 0.90))
plot(UKMET.pre2007.10yrpred)
write.csv(UKMET.pre2007.10yrpred, 'UKMET.pre2007.csv')
```

#1999 Forecasts

```{r}
NASA.1999 <- head(NASA.Long,-255)
NASA.1999.TS <- ts(NASA.1999$Temp, start = 1880, frequency = 12)
fit.auto.arima.season <- auto.arima(NASA.1999.TS,seasonal=TRUE)
fit.auto.arima.season
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,132)) 
#120 stands for 120 months = 10 years
```



```{r}
NASA.1999.10yrpred <- forecast(fit.auto.arima.season,h=120, level=c(0.8, 0.90))
plot(NASA.1999.10yrpred)
write.csv(NASA.1999.10yrpred, 'ASA.1999.10yr.csv')

NASA.1999.20yrpred <- forecast(fit.auto.arima.season,h=240, level=c(0.8, 0.90))
plot(NASA.1999.20yrpred)
write.csv(NASA.1999.20yrpred, 'NASA.1999.20yr.csv')
```



```{r}
UKMET.1999 <- head(UKMET.Long,-253)
UKMET.1999.TS <- ts(UKMET.1999$Temp, start = 1850, frequency = 12)

fit.auto.arima.season <- auto.arima(UKMET.1999.TS,seasonal=TRUE)
fit.auto.arima.season
```



```{r}
par(mfrow=c(1,1))
Acf(residuals(fit.auto.arima.season))
plot(forecast(fit.auto.arima.season,120)) 
#120 stands for 120 months = 10 years
```


```{r}
UKMET.1999.10yrpred <- forecast(fit.auto.arima.season,h=120, level=c(0.8, 0.90))
plot(UKMET.1999.10yrpred)
write.csv(UKMET.1999.10yrpred, 'UKMET.1999.10yr.csv')
```


```{r}
UKMET.1999.20yrpred <- forecast(fit.auto.arima.season,h=240, level=c(0.8, 0.90))
plot(UKMET.1999.20yrpred)
write.csv(UKMET.1999.20yrpred, 'UKMET.1999.20yr.csv')
```

